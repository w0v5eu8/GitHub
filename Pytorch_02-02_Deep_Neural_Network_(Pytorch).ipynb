{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Second_Week_Seong_Nam_Final_distributed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXeQQ-goukiT",
        "colab_type": "text"
      },
      "source": [
        "#**Deep Learning with PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1KOEbyJuxHG",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "1. 데이터 로딩\n",
        "    + Dataset class, Transforms, DataLoader, Data visualization in PyTorch\n",
        "2. 모델 정의하기\n",
        "    + PyTorch를 사용하여 심층 신경망(DNN) 구축하기\n",
        "3. Training and Evaluation\n",
        "    + Loss 계산과 Backpropagation 실행을 통한 모델 업데이트\n",
        "    + 학습된 모델의 성능 측정\n",
        "4. 결과 그리기\n",
        "5. Applications\n",
        "    + 활성화 함수(activation function) 없이 선형 레이어(fully-connected layer) 만을 사용한 네트워크를 학습하고 이전 결과와 비교\n",
        "    + 다른 optimizer method들(SGD with momentum, Adam과 같은)을 사용해보고 결과 확인하기\n",
        "    + Overfitting 방지를 위한 Regularization 기술들\n",
        "    + 더 복잡한 데이터 셋(CIFAR10)에서의 실험\n",
        "    \n",
        "6. Reference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EkxOnfiMDGg",
        "colab_type": "text"
      },
      "source": [
        "## 1. 데이터 로딩(Data Loading)\n",
        "- 사용하고자 하는 데이터 셋을 원할하게 로딩(loading) 시키기 위해서는, 먼저 PyTorch에서 제공하는 `Dataset Class`, `Transforms`, `DataLoader`에 친숙해져야 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyC3hLCmWIXA",
        "colab_type": "text"
      },
      "source": [
        "1) Dataset Class\n",
        "- `Dataset Class` 는 데이터셋을 나타내는 추상클래스이다. 우리가 임의로 만드는 데이터셋은 `Dataset`을 상속하고 아래와 같이 오버라이드(override)해야 한다.\n",
        " - `len(dataset)` 에서 호출되는 `__len__`은 데이터셋의 크기를 리턴해야함.\n",
        " - `dataset[i]`에서 호출되는 `__getitem__`은 $i$번째 샘플을 찾는데 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHAMprW8XZ76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Examples of Dataset Class\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class MyDataset(Dataset): #Inherit Dataset\n",
        "    def __init__(self, input, label, transforms=None):\n",
        "        self.input = input\n",
        "        self.label = label\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.input[idx]\n",
        "        y = self.label[idx]\n",
        "\n",
        "        if self.transforms:\n",
        "            x,y = self.transforms((x,y))\n",
        "\n",
        "        return x, y\n",
        "\n",
        "input = np.random.randn(5,3)\n",
        "label = np.array([i for i in range(5)]).reshape(5,1)\n",
        "\n",
        "dataset = MyDataset(input, label)\n",
        "print('The size of dataset:', len(dataset))\n",
        "print('1st data sample: ', dataset[0])\n",
        "print('3rd data sample: ', dataset[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk2l5X8Pq007",
        "colab_type": "text"
      },
      "source": [
        "2) Transforms\n",
        "- 우리가 사용하는 데이터셋의 이미지들은 각기 다른 크기를 가질 수도 있으며, 정규화(normalize) 시킬 필요가 있을 수도 있으며, PyTorch에서 모델에 들어가기 위해서는 tensor형으로 변환도 시켜줘야한다. 따라서 우리는 데이터셋의 샘플을 전처리(preprocessing) 시킬 필요가 있으며 이를위해 PyTorch에서 제공하는 기본 변환(transform) 방법들을 다음과 같이 소개한다:\n",
        " - `ToTensor` : numpy 이미지를 tensor 이미지로 변환 (Pytorch에서 네트워크에 입력을 집어넣으려면 tensor 변환은 필수적이다.)\n",
        " - `Resize`: 입력 PIL 이미지를 주어진 크기로 조정 (각 이미지 마다 크기가 다를때 사용)\n",
        " - `Normalize` : 주어진 평균 및 표준 편차로 텐서 이미지를 정규화\n",
        "  - `RandomCrop` : 이미지를 랜덤적으로 잘라낸다. Data augmentation을 위해 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py1rRnf_bm8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define Tranforms \n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        input, label = sample\n",
        "        return torch.from_numpy(input), torch.from_numpy(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk_pG2TvdQKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The use of Transforms\n",
        "\n",
        "dataset = MyDataset(input, label, ToTensor())\n",
        "print('1st data sample : ', dataset[0])\n",
        "print('3rd data sample : ', dataset[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwKTmM0BfCh4",
        "colab_type": "text"
      },
      "source": [
        "**-그러나 PyTorch에서는 보편적 데이터셋(ImageNet, CIFAR10, MNIST 등의)을 위한 데이터 로더(Data Loader)와 데이터 변환(Data Transform)기능들을 편리하게 제공하는 torchvision이라는 패키지를 제공한다.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD1nmRAt0D9o",
        "colab_type": "text"
      },
      "source": [
        "그러면 이를 이용하여 오늘 강의에서 사용하게 될 MNIST 데이터셋을 로드해보자.\n",
        "\n",
        "\\* MNIST 데이터 세트는 0에서 9 사이의 손으로 쓴 한 자리 숫자의 28 * 28 pixel grayscale 이미지로 구성된 데이터 세트이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueIgjM9qZvaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "torch.manual_seed(2020) # 시드를 고정\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True) # The output of torchvision datasets are PILImage images of range [0,1]. We transforms them to Tensors of normalized range [-1,1] Using ToTensor()\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Sxg_RfEwTW",
        "colab_type": "text"
      },
      "source": [
        "다음과 같이 학습 및 테스트 데이터 세트의 크기를 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGBWM6PErps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\nThe size of training dataset :', len(train_dataset))\n",
        "print('\\nThe size of test dataset :', len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfSR1c12WJ2X",
        "colab_type": "text"
      },
      "source": [
        "3) DataLoader\n",
        "\n",
        "- 실제로 DNN을 학습시킬때는 한번의 update에 모든 데이터 샘플을 사용하는 batch gradient를 이용하는 대신 한번의 update에 batch 단위의 샘플이 사용되는 mini batch gradient를 이용하게 된다. 이를 위해 데이터를 batch 단위로 분리하고 셔플(Shuffle)해야하는데 이는 PyTorch의 `DataLoader`에 의해 수행된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Ng0qmdWVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64 # Batch size 설정\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) # Shuffle argument controls data shuffling for stochastic gradient descent\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataiter = iter(train_loader)  # iter() 메소드는 iterable object를 반환한다. (즉, loop 문 사용이 가능하다)\n",
        "inputs, labels = dataiter.next()\n",
        "\n",
        "print(inputs.shape) #데이터 로더에 의해 한배치의 shape은 (배치사이즈, 채널 수, 높이, 폭)와 같이 된다.\n",
        "print(labels.shape)\n",
        "\n",
        "# 보통 아래와 같이 사용한다.\n",
        "for (images, labels) in train_loader:\n",
        "    #print(images.shape)\n",
        "    #print(labels.shape)\n",
        "    ####################\n",
        "    #    statements  \n",
        "    ####################\n",
        "    break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0GdIBLPiWbp",
        "colab_type": "text"
      },
      "source": [
        "4) Data Visualization\n",
        "- 우리는 입력 이미지를 시각화 할 수 있으며 다음과 같은 코드로 이를 구현할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-y81wPWDMd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "inputs, labels = dataiter.next()\n",
        "\n",
        "figure = plt.figure()\n",
        "plt.imshow(inputs[0].numpy().squeeze(), cmap='gray_r') # We can see a first image of a batch\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3VZypEVYbep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_show(input):\n",
        "    input = input.numpy()\n",
        "    plt.imshow(np.transpose(input, (1,2,0)).squeeze(), cmap='gray_r')\n",
        "    plt.show()\n",
        "\n",
        "image_show(torchvision.utils.make_grid(inputs)) # We can see all 64 images of a batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4-4tBpMGsNp",
        "colab_type": "text"
      },
      "source": [
        "## 2. Defining our Model\n",
        "\n",
        "- 이번 실습에서는 Multi-classification Task를 진행해 볼것이며, 이를 위해 작은 MLP 모델(Fully-Connected Layers로만 구성된)을 구축 할 것이다. \n",
        "- 지난 시간에 배웠듯이, Fully-Connected Layer에서는 다음과 같은 선형 연산이 이루어진다.\n",
        "\n",
        " $\\mathbf{Y} = \\mathbf{X}\\mathbf{W} + \\mathbf{b}$ where $\\mathbf{W} \\in \\mathbf{R}^{ \\ previous\\_layer\\_size \\times next\\_layer\\_size}$ and $\\mathbf{b}$ $\\in \\mathbf{R}^{next\\_layer\\_size}$\n",
        "\n",
        "- Fully-Connected layer를 통과하고 나면, 마지막 output layer를 제외하고 non-lineariry를 주기위해 activation function(e.g., ReLU)이 사용된다. \n",
        " + ReLU(x) = max(0,x)\n",
        "\n",
        "- Multi-class classification에서는 output layer에서 Softmax function이 사용된다.\n",
        " + $\\tilde{y}_{i}$ = $[Softmax(x)]_i$ = $\\frac{e^{x_i}}{\\sum_{j=1}^{C}e^{x_k}}$ where $x = [x_1, x_2, \\ldots, x_C]$ 이며 C는 class의 개수이다.\n",
        "\n",
        "\n",
        "그러면, 다음과 같이 3 개의 Fully-Connected 레이어로 구성된 MLP 모델을 만들어 보자.\n",
        "\n",
        "![그림2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIynK-Qgjn6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mynetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Mynetwork, self).__init__()\n",
        "        # torch.nn.Linear(size of each input sample, size of each output sample)\n",
        "        self.fc1 = nn.Linear(784, 390) # Input size는 784 (28*28*1), output size는 첫번째 hidden layer의 크기로 설정 되야 한다.\n",
        "        self.fc2 = nn.Linear(390, 200) # Input size는 첫번째 hidden layer의 크기로, output size는 두번째 hidden layer의 크기로 설정 되야 한다.\n",
        "        self.fc3 = nn.Linear(200, 10) # Input size는 두번째 hidden layer의 크기로, output size는 10(클래스의 개수)로 설정 되야 한다. \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 1*28*28) # Fully-connected layer에 넣기 위해 Shape을 ([batch_size, channels, row, col]) 에서 [batch_size, channels*row*col] 로 바꾼다.\n",
        "        x = F.relu(self.fc1(x)) # Fully-connected layer를 통과시키고 Relu function(Activation function)을 통과 시킨다.\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x) # Softmax function is not applied here.\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nTEhh8SnwRg",
        "colab_type": "text"
      },
      "source": [
        "Then, let's check our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZzQBXihobUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Mynetwork()\n",
        "input_test = torch.randn(64,1,28,28)  # shape: (배치사이즈, 채널 수, 높이, 폭)\n",
        "output = model(input_test)  # output shape: (배치사이즈, 아웃풋 뉴런 수)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVo-hM9IpS5W",
        "colab_type": "text"
      },
      "source": [
        "## 3. Training and Evaluation\n",
        "Training : 데이터를 로딩이 완료되고 사용할 모델을 정의 하였다면, 이를 이용하여 딥 뉴럴 네트워크를 학습 시킬 수 있다.\n",
        "- Training에 필요한 파라미터를 설정한 후,\n",
        "- 1) 입력 값을 모델에 통과시켜 output을 얻고 \n",
        "- 2) 이러한 output과 실제 label을 비교하여 loss를 계산한다.\n",
        "- 3) Backpropagation을 실행하여 그래디언트 값을 계산한다.\n",
        "- 4) 계산된 그래디언트를 이용하여 모델을 업데이트한다.\n",
        "\n",
        "Evaluation : Training 종료 후 얻은 모델을 사용하여 입력에 대한 예측을 수행하고 Evaluation metrics(예를 들면, accuracy와 같은)을 계산하여 우리가 얻은 모델의 성능을 측정 할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbWZB-jPYcXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "################## 데이터 로드/ 모델 구축 ##################\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "\n",
        "##################################################\n",
        "\n",
        "###################################################\n",
        "\n",
        "batch_size = 64 # Batch size 설정\n",
        "\n",
        "#train loader와 test loader 만들기\n",
        "\n",
        "##################################################\n",
        "\n",
        "###################################################\n",
        "\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #GPU 사용이 가능하면 cuda 반환\n",
        "\n",
        "#위에서 정의한 모델로 만들기\n",
        "model1 = Mynetwork()\n",
        "model1.to(device) # GPU 사용이 가능하면 model을 GPU로 옮긴다.\n",
        "\n",
        "################## Training을 위한 변수 설정 ##################\n",
        "\n",
        "# Epoch 설정\n",
        "num_epoch = 15\n",
        "\n",
        "# 우리가 하려는 Task에 부합하는 Loss의 종류를 결정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#사용할 optimizer의 종류를 선택하고 learning rate 설정\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDQPJHmVr8k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################## Training ##################\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "\n",
        "    model.train() # training mode \n",
        "    # dropout이나 batch-normalization을 사용하는 모델의 레이어는 현재 모드(training 또는 evaluation)에 따라 다르게 동작해야한다.\n",
        "    \n",
        "    losses_batch = []\n",
        "\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device) # GPU사용이 가능하면 data를 GPU로 옮긴다.\n",
        "        optimizer.zero_grad() # Optimizer의 gradient를 초기화 한다.\n",
        "         # 1) forward pass를 진행한다.\n",
        "         # 2) 예측 output과 실제 label을 비교하여 loss를 계산한다\n",
        "        losses_batch.append(loss)\n",
        "         # 3) Backpropagation을 실행하여 그래디언트 값을 계산한다.\n",
        "         # 4) 계산된 그래디언트를 이용하여 모델을 업데이트한다.\n",
        "\n",
        "    loss_epoch = sum(losses_batch)/len(losses_batch)\n",
        "\n",
        "    return loss_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_ixrckVxZIv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UmMcia9uoHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################## Evaluation ##################\n",
        "\n",
        "def eval(model, device, test_loader):\n",
        "     \n",
        "    model.eval() # evaluation mode\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad(): # Test 때에는 gradient값이 필요하지 않으므로 연산 추적을 멈춘다.\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device) \n",
        "            outputs = model(inputs) \n",
        "            _, predicts = torch.max(outputs.data , 1) # 예측 label 생성 \n",
        "            total += labels.size(0)\n",
        "            correct += (predicts==labels).sum().item() # 예측 label과 실제 label을 비교하여 accuracy 측정\n",
        "    \n",
        "    Accuracy = 100*correct/total\n",
        "\n",
        "    print('Test Accuracy: {:.2f}%'.format(Accuracy))\n",
        "    return Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s3zGIYzsayi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement training and evaluation\n",
        "\n",
        "train_loss_epoch = []\n",
        "test_acc_epoch = []\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch.append(train(model1, device, train_loader, optimizer, criterion)) \n",
        "    test_acc_epoch.append(eval(model1, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PApwxp3IFL9t",
        "colab_type": "text"
      },
      "source": [
        "## 4. 결과 그리기\n",
        " - matplotlib 라이브러리를 사용하여 위에서 얻은 결과를 그릴 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lko86CA582Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "f1 = figure.add_subplot(221)\n",
        "f2 = figure.add_subplot(222)\n",
        "\n",
        "epochs = range(num_epoch)\n",
        "\n",
        "f1.plot(epochs, train_loss_epoch)\n",
        "f1.set_title('Training loss over epoch')\n",
        "f1.set_xlabel('Epoch')\n",
        "f1.set_ylabel('Training Loss')\n",
        "\n",
        "\n",
        "f2.plot(epochs, test_acc_epoch)\n",
        "f2.set_title('Test Accuracy over epoch')\n",
        "f2.set_xlabel('Epoch')\n",
        "f2.set_ylabel('Test Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDhrv-k1GSRt",
        "colab_type": "text"
      },
      "source": [
        "## 5. Applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOZGB242HDLw",
        "colab_type": "text"
      },
      "source": [
        "### 1) 활성화 함수(activation function) 없이 선형 레이어(fully-connected layer) 만을 사용한 네트워크의 학습 및 이전 결과와의 비교\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16QfnX4GUV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Only_Linear_Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Only_Linear_Model, self).__init__()\n",
        "        # torch.nn.Linear(size of each input sample, size of each output sample)\n",
        "        self.fc1 = nn.Linear(784,390) \n",
        "        self.fc2 = nn.Linear(390, 200) \n",
        "        self.fc3 = nn.Linear(200, 10) \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 1*28*28) \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model2 = Only_Linear_Model()\n",
        "model2.to(device)\n",
        "\n",
        "num_epoch = 15\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_loss_epoch_Linear = []\n",
        "test_acc_epoch_Linear = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_Linear.append(train(model2, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_Linear.append(eval(model2, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Y5UBPAHakJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "f1 = figure.add_subplot(221)\n",
        "f2 = figure.add_subplot(222)\n",
        "\n",
        "epochs = range(num_epoch)\n",
        "\n",
        "f1.plot(epochs, train_loss_epoch[:15], label='Non-Linear Model')\n",
        "f1.plot(epochs, train_loss_epoch_Linear, label='Linear Model')\n",
        "f1.legend()\n",
        "f1.set_title('Training loss over epoch')\n",
        "f1.set_xlabel('Epoch')\n",
        "f1.set_ylabel('Training Loss')\n",
        "\n",
        "f2.plot(epochs, test_acc_epoch[:15],  label='Non-Linear Model')\n",
        "f2.plot(epochs, test_acc_epoch_Linear,  label='Linear Model')\n",
        "f2.legend()\n",
        "f2.set_title('Test Accuracy loss over epoch')\n",
        "f2.set_xlabel('Epoch')\n",
        "f2.set_ylabel('Test Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP1p5xAbHIw6",
        "colab_type": "text"
      },
      "source": [
        "### 2) 다른 optimizer method들(SGD with momentum, Adam과 같은)의 사용 및 결과 확인\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAIy2TQFHK5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SGD with momentum\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_momentum = Mynetwork()\n",
        "model_momentum.to(device)\n",
        "\n",
        "num_epoch = 15\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_momentum.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "train_loss_epoch_momentum = []\n",
        "test_acc_epoch_momentum = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_momentum.append(train(model_momentum, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_momentum.append(eval(model_momentum, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMSZNID9H_06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adam\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_Adam = Mynetwork()\n",
        "model_Adam.to(device)\n",
        "\n",
        "num_epoch = 15\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_Adam.parameters(), lr=0.001, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "train_loss_epoch_Adam = []\n",
        "test_acc_epoch_Adam = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_Adam.append(train(model_Adam, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_Adam.append(eval(model_Adam, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpQGBopPJOdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "f1 = figure.add_subplot(221)\n",
        "f2 = figure.add_subplot(222)\n",
        "\n",
        "epochs = range(num_epoch)\n",
        "\n",
        "f1.plot(epochs, train_loss_epoch[:15], label='SGD')\n",
        "f1.plot(epochs, train_loss_epoch_momentum, label='SGD with momentum')\n",
        "f1.plot(epochs, train_loss_epoch_Adam, label='Adam')\n",
        "f1.legend()\n",
        "f1.set_title('Training loss over epoch')\n",
        "f1.set_xlabel('Epoch')\n",
        "f1.set_ylabel('Training Loss')\n",
        "\n",
        "f2.plot(epochs, test_acc_epoch[:15],  label='SGD ')\n",
        "f2.plot(epochs, test_acc_epoch_momentum,  label='SGD with momentum')\n",
        "f2.plot(epochs, test_acc_epoch_Adam,  label='Adam')\n",
        "f2.legend()\n",
        "f2.set_title('Test Accuracy loss over epoch')\n",
        "f2.set_xlabel('Epoch')\n",
        "f2.set_ylabel('Test Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZV6rHFhqXn2",
        "colab_type": "text"
      },
      "source": [
        "### 3) Overfitting 방지를 위한 Regularization 기술들\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceRwEB56qflm",
        "colab_type": "text"
      },
      "source": [
        "#### 1.Weight Decay - L2 (Ridge) regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2z1Qo7krYk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#L2 (Ridge) regularization\n",
        "\n",
        "model_L2 = Mynetwork()\n",
        "model_L2.to(device)\n",
        "\n",
        "num_epoch = 15\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_L2.parameters(), lr=0.001, weight_decay=0.05) # weight decay parameter(lambda)에 값을 넣어 줌으로써 L2 regularization 효과를 준다.\n",
        "\n",
        "\n",
        "train_loss_epoch_L2 = []\n",
        "test_acc_epoch_L2 = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_L2.append(train(model_L2, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_L2.append(eval(model_L2, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6UmuIxOqo4F",
        "colab_type": "text"
      },
      "source": [
        "#### 2.Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI248DNGsVKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropout\n",
        "\n",
        "class Mynetwork_dropout(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Mynetwork_dropout, self).__init__()\n",
        "        self.fc1 = nn.Linear(784,390) \n",
        "        self.fc2 = nn.Linear(390, 200) \n",
        "        self.fc3 = nn.Linear(200, 10) \n",
        "        self.dropout = nn.Dropout(p=0.2) # training 중에는 p의 확률로 입력 텐서의 일부 요소를 무작위로 0으로 만든다.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 1*28*28)\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x) \n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5n0oelk2HG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_dropout = Mynetwork_dropout()\n",
        "model_dropout.to(device)\n",
        "\n",
        "num_epoch = 15\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_dropout.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_loss_epoch_DO = []\n",
        "test_acc_epoch_DO = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_DO.append(train(model_dropout, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_DO.append(eval(model_dropout, device, test_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QQ8uSCfDVdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "f1 = figure.add_subplot(221)\n",
        "f2 = figure.add_subplot(222)\n",
        "\n",
        "epochs = range(num_epoch)\n",
        "\n",
        "f1.plot(epochs, train_loss_epoch_L2, label='SGD with L2 regularization')\n",
        "f1.plot(epochs, train_loss_epoch_DO, label='SGD with Dropout')\n",
        "\n",
        "f1.legend()\n",
        "f1.set_title('Training loss over epoch')\n",
        "f1.set_xlabel('Epoch')\n",
        "f1.set_ylabel('Training Loss')\n",
        "\n",
        "f2.plot(epochs, test_acc_epoch_L2,  label='SGD with L2 regularization')\n",
        "f2.plot(epochs, test_acc_epoch_DO,  label='SGD with Dropout')\n",
        "\n",
        "f2.legend()\n",
        "f2.set_title('Test Accuracy loss over epoch')\n",
        "f2.set_xlabel('Epoch')\n",
        "f2.set_ylabel('Test Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDTGZDefHLd8",
        "colab_type": "text"
      },
      "source": [
        "### 4) 더 복잡한 데이터 셋(CIFAR10)에서의 실험\n",
        " - CIFAR10 dataset은 60000개 (50000개는 Training dataset, 10000개는 test dataset)의 32*32 pixel 컬러이미지들로 구성되어 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMttssjeEHDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Data loading\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.RandomHorizontalFlip(), # 주어진 확률로 주어진 이미지를 무작위로 수평 뒤집는다. (Defualt는 0.5) # Data augementation을 위해 사용된다.\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
        ")\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2) #num_workers는 데이터 로딩을 위해 몇개의 CPU 코어를 사용할 것인지를 결정.\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=2 )  # 코어를 많이 할당할수록 데이터 로딩은 빨라지지만 다른 부가적인 처리에 딜레이가 생기므로 적절한 밸런스를 유지 하는 것이 필요.\n",
        "\n",
        "#Define model\n",
        "class model_cifar(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_cifar, self).__init__()\n",
        "         # input size가 (3*32*32)이고 output size가 1024인 linear layer 만들기\n",
        "         # input size가 1024이고 output size가 512인 linear layer 만들기\n",
        "         # input size가 512이고 output size가 128인 linear layer 만들기\n",
        "         # input size가 128이고 output size가 10인 linear layer 만들기\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(x.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = model_cifar()\n",
        "model.to(device) #Move model to gpu\n",
        "\n",
        "#Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "#Training and Evaluation\n",
        "num_epoch = 15\n",
        "\n",
        "train_loss_epoch_cifar = []\n",
        "test_acc_epoch_cifar = []\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_loss_epoch_cifar.append(train(model, device, train_loader, optimizer, criterion))\n",
        "    test_acc_epoch_cifar.append(eval(model, device, test_loader))\n",
        "\n",
        "\n",
        "\n",
        "#Plot the results\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "f1 = figure.add_subplot(221)\n",
        "f2 = figure.add_subplot(222)\n",
        "\n",
        "epochs = range(num_epoch)\n",
        "\n",
        "f1.plot(epochs, train_loss_epoch_cifar, label='SGD with momentum')\n",
        "\n",
        "f1.legend()\n",
        "f1.set_title('Training loss over epoch on CIFAR10')\n",
        "f1.set_xlabel('Epoch')\n",
        "f1.set_ylabel('Training Loss')\n",
        "\n",
        "f2.plot(epochs, test_acc_epoch_cifar,  label='SGD with momentum')\n",
        "\n",
        "f2.legend()\n",
        "f2.set_title('Test Accuracy loss over epoch on CIFAR10')\n",
        "f2.set_xlabel('Epoch')\n",
        "f2.set_ylabel('Test Accuracy')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqwuOY2EHka-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b250ZohtRZqe",
        "colab_type": "text"
      },
      "source": [
        "## 6. Reference\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataset%20dataloader\n",
        "\n",
        "https://wikidocs.net/57165\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDr4klJWRdJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}